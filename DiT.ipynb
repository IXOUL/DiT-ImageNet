{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958b1977",
   "metadata": {},
   "source": [
    "### Patchify\n",
    "cut 2D image $H*W*C$ ($H$ height, $W$ width, $C$ channel) into many patches, flattening the patch and project it into dimension $D$, getting a series of tokens for transformer to operate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0bbd9",
   "metadata": {},
   "source": [
    "Code reference: \n",
    "\n",
    "I read the original paper about the logic of the Patchify in ViT, and searched for other people's work of writing it.\n",
    "\n",
    "https://github.com/vballoli/vit-flax/blob/main/vit_flax/vit.py\n",
    "\n",
    "ChatGPT learning the functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    patch_size: int\n",
    "    dimension: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # x: shape (B, H, W, C)\n",
    "        B, H, W, C = x.shape\n",
    "        patches_h = H // self.patch_size\n",
    "        patches_w = W // self.patch_size\n",
    "        total_num_patches = patches_h * patches_w\n",
    "        \n",
    "        # 1. reshape the images into patch grids\n",
    "        # -> (B, patches_h, patch, patches_w, patch, C)\n",
    "        x = x.reshape(B, patches_h, self.patch_size, patches_w, self.patch_size, C)\n",
    "\n",
    "        # 2. transpose to bring patch dimensions together\n",
    "        # -> (B, patches_h, patches_w, patch, patch, C)\n",
    "        x = jnp.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "\n",
    "        # 3. flatten patch pixels -> (B, total_num_patches, patch_size*patch_size*C)\n",
    "        x = x.reshape(B, total_num_patches, self.patch_size * self.patch_size * C)\n",
    "\n",
    "        # 4. linear projection to \"dimension\" for Transformer\n",
    "        x = nn.Dense(self.dimension)(x)\n",
    "\n",
    "        # 5. learned positional embedding\n",
    "        pos = self.param(\"pos\", nn.initializers.normal(0.02), (1, total_num_patches, self.dim))\n",
    "        x = x + pos\n",
    "\n",
    "        return x, (patches_h, patches_w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_DiT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
